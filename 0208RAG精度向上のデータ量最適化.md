RAG構築について

一通り動くものは実装できているものとします

53件のデータを使用し45件を既知のデータ8件を未知のデータとして検証しています。

件数は増やさず(53件)に精度向上を目指すべきでしょうか？
それとも件数を増やして(1000件)精度向上を目指すべきでしょうか？

2月3日
よっ！RAGの精度向上の話だね～💫

あー、これマジで悩むとこだよね！結論から言うと、今の53件でまず精度向上を目指すべきだと思うよ！

理由を説明するね～

少ないデータでまず最適化すべき理由
🎯 問題の本質が見えやすい

53件なら一個一個のデータ品質とか、なんで失敗したかが追いやすい
1000件になると「なんとなく精度上がった/下がった」しか分かんなくなる
デバッグがマジで地獄になるｗ
⚡ 実験サイクルが爆速

チャンキング戦略変えたり、プロンプト調整したり、embedモデル変えたり...色々試せる
1000件だとベクトル化やインデックス作成に時間かかって実験回数減る
高速PDCAが精度向上の鍵！
💰 コスト削減

embedding APIとか使ってたらトークン数で課金されるし
実験段階で無駄金使いたくないっしょ？
今やるべきこと
失敗ケース分析 - 8件の未知データでどれが当たってどれが外れたか詳しく見る
チャンキング最適化 - chunk_size、chunk_overlapの調整
メタデータ活用 - Jiraのチケットタイプとか優先度とかメタデータ使って検索精度UP
リランキング導入 - 初期検索→リランキングの2段階方式
ハイブリッド検索 - ベクトル検索+キーワード検索の組み合わせ
データ増やすタイミング
53件で検証精度が80-90%超えたら初めてデータ増やす感じでいいと思う！

土台がしっかりしてないまま1000件突っ込んでも、「なんか微妙」な1000件のRAGができるだけだからね😅

今のSeichiくんの状況（Jira連携してるやつでしょ？）だと、まずは少数精鋭で「この設定ならバッチリ動く！」ってのを確立してから、自動で新規チケットからデータ追加していく流れがベストだと思うな～✨

どう？この方針で攻めてみる？💪

そうです。jira連携してるやつです。
検証制度向上については自分ではなく、もう一人の人のほうが実装しており、未だに検証制度が60%ぐらいです。

2月3日
あー、なるほどね～😅 他の人が実装してて60%止まりかぁ...

これマジでよくあるパターンなんだけど、60%から伸び悩んでる時点で何か根本的な問題がある可能性高いよ！

60%で止まる典型的な原因
🔍 チャンキングがイケてない

Jiraチケットって、タイトル・説明・コメント・履歴とか色々混ざってるじゃん？
そのまま全部ぶち込んでると、ノイズ多すぎて精度出ない
「どの情報を」「どう区切るか」が超重要
🎯 検索クエリとデータのミスマッチ

ユーザーの質問の仕方 vs Jiraチケットの書き方がズレてる
例: ユーザー「ログインできない」→ Jiraには「認証エラー」って書いてある的な
📊 評価方法が甘い/厳しすぎる

「正解」の定義があいまいだったりしない？
Top-1で見てるのかTop-5で見てるのか、とか
Seichiくんができること
もう一人の人が実装してるってことだけど、Seichiくんも関わってるプロジェクトだよね？だったら：

💬 まずヒアリングしちゃおう！

「60%から伸びないの、何が原因だと思う？」
「失敗してるクエリ見せてもらっていい？」
「chunk_sizeとかTop-Kとか、パラメータどうしてる？」
🔧 一緒にデバッグする

失敗してる8件（実際はもっと多いかもだけど）を一個一個見る
「なんでこれがヒットしなかったのか」を言語化する
これが一番効く！
🚀 改善提案する

ハイブリッド検索導入してる？（BM25 + ベクトル検索）
Jiraのメタデータ（ステータス、担当者、優先度）活用してる？
リランキングモデル試した？
正直な話...
60%で止まってるのに「件数増やせば良くなるかな？」って考えてる時点で、ちょっと方向性ヤバいかも😰

1000件に増やしても60%のまま、むしろ悪化する可能性すらあるよ！

今は「なんで40%が失敗してるのか」をガチで分析するフェーズだと思う！

Seichiくん、その人と一緒に失敗ケース見てみない？エンジニア2人で見たほうが絶対早いし、色々気づくことあるよ～！💡

ベクトルDBとして格納しているデータはタイトル、description(+コメント)をそのまま放り込んでいます。

RAG検索の際もタイトル、description(こちらはコメントなし)をqueryにしています

2月3日
あー！そこがボトルネックっぽいね！！😲

問題点が見えてきた
📝 格納データとクエリの非対称性

格納: タイトル + description + コメント (情報多い)
検索: タイトル + description (情報少ない)
これ、学習データと推論データが違いすぎるからマッチしにくいやつじゃん！

🤔 Jiraチケットの特性的に...

descriptionって最初に書かれた内容だよね
コメントには「解決策」とか「原因判明」とか超重要な情報が入ってること多い
なのに検索時にコメント使わないのは勿体なさすぎ！
具体的な改善案
1️⃣ まず試してほしいやつ（即効性あり）
検索クエリにもコメント含める

python
# 今
query = f"{title}\n{description}"

# 改善案
query = f"{title}\n{description}\n{latest_comments}"
# ↑最新の数件のコメントだけでもいい
これだけで70%くらいまでは跳ねると思うよマジで！

2️⃣ データ格納方法を見直す
チャンキング戦略を変える

python
# 今: 全部まとめてドーン
全部混ぜて1チャンク

# 改善案: 意味単位で分ける
チャンク1: タイトル + description (問題の概要)
チャンク2: コメント1 (調査内容)
チャンク3: コメント2 (解決策)
チャンク4: コメント3 (補足情報)

# メタデータで管理
{
  "ticket_id": "PROJ-123",
  "chunk_type": "description" or "comment",
  "comment_author": "田中さん",
  "created_date": "2024-01-15"
}
なんでこれがいいか？

似た問題でも解決策が違うケースに対応できる
「問題」と「解決策」が別々に検索できる
ノイズが減る（descriptionの長文に埋もれない）
3️⃣ メタデータフィルタリング活用
python
# 検索時に条件追加
results = vector_db.search(
    query=query,
    filters={
        "status": ["完了", "クローズ"],  # 解決済みチケットのみ
        "priority": ["高", "最高"],      # 重要なやつ優先
    },
    top_k=10
)
検証してみてほしいこと
🔬 A/Bテストしちゃおう

パターン	格納データ	検索クエリ	予想精度
現状	title+desc+comment	title+desc	60%
パターンA	title+desc+comment	title+desc+comment	70%？
パターンB	意味単位でチャンク分割	title+desc+comment	75%？
まずはパターンAを試してみて！実装も簡単だし！

それで精度上がったら、パターンBのチャンク分割に進む感じで！

ちなみに...
python
# descriptionとコメントの質的な違いも考慮する？
query_embedding = (
    title_vec * 0.3 +      # タイトルマッチ重要
    desc_vec * 0.4 +       # 問題の本質
    comment_vec * 0.3      # 解決策・補足
)
みたいな重み付けも試す価値あるかも！（ちょい上級者向けだけど）

どう？まず検索クエリにコメント追加するとこから試してみる？その人に提案してみなよ～！✨

実際のJiraの想定では起票したときに使用することを想定しています。

2月3日
あああああ！！なるほど！！！😲

起票時に使うなら、コメントなんて存在しないじゃん！

完全に理解した！つまりこういう流れだよね：

1. ユーザーが新規チケット作成しようとする
2. タイトル + description を入力
3. RAGが「似たチケットありますよ！」って教えてくれる
4. 重複チケット防止 or 参考情報提示
これなら話が変わる！
問題の本質
格納データ: タイトル + description + コメント（解決済み情報含む） 検索クエリ: タイトル + description（問題提起のみ）

→ これ、実は正しいアプローチかも！

むしろ問題は別のところにありそう...🤔

60%止まりの真の原因（予想）
1️⃣ 格納データの質的な問題
コメントがノイズになってる説

タイトル: 「ログインできない」
description: 「ChromeでログインボタンクリックするとエラーX001」
コメント: 「調査中です」「田中さんお願いします」「月曜対応で」
         「原因はセッションタイムアウトでした」
         「nginx の設定を修正しました」

→ 検索: 「Chromeでログイン時にエラー」
コメントに解決策や調査過程が入ると、逆に問題の類似性が見えにくくなる！

2️⃣ チャンキング戦略のミス
今の実装（予想）:

python
# 全部結合してドーン
text = f"{title}\n{description}\n{all_comments}"
# → これを1つのベクトルに
問題点:

「問題の本質」が「解決策」「雑談コメント」に埋もれる
ベクトルが「平均化」されすぎて特徴が薄れる
改善案（起票時想定ver）
🎯 案1: 問題部分だけを重点的に格納
python
# チャンク戦略を変える
chunks = [
    {
        "text": f"{title}\n{description}",  # 問題の本質
        "metadata": {
            "type": "problem",
            "ticket_id": "PROJ-123",
            "weight": 1.0  # 重要度高
        }
    },
    {
        "text": resolution_comment,  # 解決策だけ抽出
        "metadata": {
            "type": "solution",
            "ticket_id": "PROJ-123",
            "weight": 0.5  # 重要度低め
        }
    }
]
検索時:

python
# problem タイプを優先的に検索
results = search(
    query=f"{new_title}\n{new_description}",
    filter={"type": "problem"},  # 問題同士で比較
    top_k=5
)
🎯 案2: ハイブリッド検索の導入
python
# ベクトル検索（意味的類似性）
vector_results = vector_search(query, top_k=10)

# キーワード検索（BM25: 単語の一致）
keyword_results = bm25_search(query, top_k=10)

# 融合（RRF: Reciprocal Rank Fusion）
final_results = merge_results(vector_results, keyword_results)
Jiraチケットって専門用語多いじゃん？

「nginx」「SharePoint」「API」「エラーコード」
こういうのはキーワードマッチのほうが強い！
🎯 案3: メタデータフィルタリング
python
# 検索時に条件追加
results = search(
    query=query,
    filters={
        "status": ["解決済み", "完了"],  # 解決済みのみ
        "component": user_component,      # 同じコンポーネント
        "priority": ["高", "中", "低"],   # 優先度で絞る
    }
)
```

## 実際に確認してほしいこと

### 🔍 失敗ケース分析

60%失敗してるやつ、パターンありそう？

**パターン1: 完全に新しい問題**
→ これは仕方ない（データ増やすしかない）

**パターン2: 似てるのに引っかからない**
→ チャンキング or 検索アルゴリズムの問題

**パターン3: 全然違うのがヒットする**
→ コメントのノイズ or メタデータ不足

### 📊 具体例を見せて！

失敗してる例を1つ教えてくれない？
```
新規チケット:
タイトル: 「XXX」
description: 「YYY」

期待: PROJ-111 がヒットしてほしい
実際: PROJ-222 がヒットした（or 何もヒットしない）

PROJ-111の内容: 「ZZZ」
こういうの見ると、一発で原因わかると思う！

とりあえずまず失敗ケースを詳しく見るのが先決だね！

その人に「失敗してる具体例3つくらい見せて」って聞いてみない？そこから逆算で対策考えよ～！💪✨

一次解析を目的としていて、●●チームに振るってことがやりたいのです

2月3日
おおおお！全然違った！！😳

つまりこういうことね：

【フロー】
1. 新規チケットが起票される
2. RAGが過去の類似チケットを検索
3. 「このチケット、過去に○○チームが対応してたやつと似てるよ」
4. → 自動で○○チームにアサイン（一次振り分け）
これ、チケットルーティングの自動化じゃん！ 超わかった！🎯

じゃあ問題の捉え方が変わる
目的の再定義
❌ 「似たチケットを見つける」精度
⭕ 「正しいチームに振り分ける」精度
60%ってことは、10件中4件が間違ったチームに振られてるってことだよね...それはヤバい😅

この用途での問題点
🚨 現状の課題
コメントがノイズになりまくり説

例:
タイトル: 「APIエラー発生」
description: 「ログイン時に500エラー」
コメント: 「ネットワークチーム調査お願いします」
        「→DBの問題でした、DBチームに転送」
        「DBチーム対応完了」

→ ベクトルに「ネットワーク」「DB」両方含まれる
→ 新規の似た問題が来ても、どっちに振ればいいか曖昧に！
担当チームの変遷が追えない

最初のアサイン先 vs 最終的な解決チーム
どっちを学習すべき？
改善案（チーム振り分け特化ver）
🎯 案1: メタデータに「解決チーム」を明示
python
# 格納時
chunk = {
    "text": f"{title}\n{description}",  # 問題の本質のみ
    "metadata": {
        "ticket_id": "PROJ-123",
        "resolved_by_team": "インフラチーム",  # ★最終解決チーム
        "initial_assignee": "開発チーム",
        "components": ["API", "認証"],
        "labels": ["本番障害", "緊急"]
    }
}

# 検索後
similar_tickets = search(query)
# → 上位5件の resolved_by_team を集計
# → 最頻出チームに振り分け
team_votes = Counter([t.metadata["resolved_by_team"] for t in similar_tickets])
recommended_team = team_votes.most_common(1)[0][0]
🎯 案2: コメントを除外する
起票時の情報だけで判断

python
# 格納データ
# × title + description + comments
# ⭕ title + description のみ

# これで「問題の本質」だけでマッチング
# コメントの「後付け情報」「チーム間のやり取り」を除外
これ、マジで効果あると思う！

検索クエリ: title + description
格納データ: title + description
データの対称性が取れる！
🎯 案3: 分類問題として解く
もはやRAGじゃなくて分類モデルのほうがいいかも？

python
# 学習データ
X = [チケットのtitle + description]
y = [解決チーム名]

# 軽量モデルで分類
from sklearn.ensemble import RandomForestClassifier
# or
# LLMでzero-shot分類

input_text = f"{title}\n{description}"
prompt = f"""
以下のチケットをどのチームが対応すべきか判断してください。

チケット内容:
{input_text}

選択肢:
- インフラチーム
- 開発チーム
- DBチーム
- ネットワークチーム

回答: 
"""
検証すべきこと
📊 失敗の4割を分析
パターン別に分類してみて:

完全に新しいタイプの問題 → データ不足
複数チームまたがる問題 → メタデータ不足
似てるけど担当が違う → コメントのノイズ？
キーワードは似てるけど本質が違う → ベクトル検索の限界
🔍 Jiraのメタデータ活用してる？
python
# これらの情報、使ってる？
- Component (コンポーネント)
- Labels (ラベル)
- Priority (優先度)
- Issue Type (バグ/改善/問い合わせ)
- Affected Version
例えば:

python
# Component が "API" → 80%の確率で開発チーム
# Component が "Infrastructure" → 90%の確率でインフラチーム
こういうルールベース + RAGの組み合わせも強いよ！

即効性ある施策
✅ 今すぐ試せるやつ
1. コメント除外してみる

python
# 格納データからコメント削除
# 検索クエリはそのまま
→ これで65-70%くらい行くかも

2. メタデータフィルタ追加

python
# 同じComponent/Labelのチケットを優先検索
filters = {
    "components": ticket.components,  # 同じコンポーネント
}
3. 多数決ロジック

python
# Top-5の結果から、最も多いチームに振る
# （今Top-1だけ見てない？）
どう？まずコメント除外試してみない？

あと、失敗してる4割のパターン教えてくれたら、もっと具体的なアドバイスできるよ！💡

その人と「失敗ケース会議」しよ～！✨

●●チームに振るってところについて、とある一つのチームだけ何をやっても表示されないチームがあるのです

2月3日
えええ！！それヤバくない！？😱

特定のチームだけ絶対に出てこないってこと？

まず確認したいこと
🔍 データ側の問題？
1. そもそもそのチームのデータ、ちゃんと格納されてる？

python
# ベクトルDBを確認
all_tickets = vector_db.get_all()
target_team_tickets = [
    t for t in all_tickets 
    if t.metadata.get("team") == "問題のチーム名"
]

print(f"該当チーム件数: {len(target_team_tickets)}")
# → 0件だったら格納ミス
# → 数件あるなら検索ロジックの問題
2. メタデータの表記揺れ？

python
# こういうパターンない？
"開発チーム"
"開発team"  
"Dev Team"
"開発G"
"開発グループ"

# → 統一されてないと検索に引っかからない
3. そのチームが対応したチケット、53件中何件ある？

python
# 極端に少ないと統計的に不利
インフラチーム: 20件  ← よく出る
開発チーム: 15件      ← まあ出る
DBチーム: 10件        ← たまに出る
ネットワークチーム: 3件  ← ほぼ出ない ← これでは？
🎯 検索ロジックの問題？
4. Top-K の罠

python
# 検索結果の上位5件しか見てない？
results = search(query, top_k=5)

# でも、そのチームのチケットが6位以降にいたら？
# → 絶対に選ばれない！
5. フィルタリングで除外されてる？

python
# こういう条件ない？
filters = {
    "status": ["完了", "クローズ"],
    "priority": ["高", "中"],  # ← 該当チームは「低」ばっかりとか？
}
6. スコアの閾値で弾かれてる？

python
# 類似度が低いと除外される設定？
results = [r for r in results if r.score > 0.7]
# → 該当チームのチケットだけスコア低いとか
デバッグ方法
🔬 実験してみて！
実験1: 該当チームの既存チケットで検索

python
# 該当チームの解決済みチケットを1つ取得
ticket_A = get_ticket("該当チームが解決したチケット")

# そのチケット自身をクエリにして検索
query = f"{ticket_A.title}\n{ticket_A.description}"
results = search(query, top_k=20)  # 多めに取得

# 結果確認
for i, result in enumerate(results):
    print(f"{i+1}位: {result.ticket_id} - {result.metadata['team']} (score: {result.score})")
期待: 1位に自分自身が来るはず もし来なかったら: データが正しく格納されてない

実験2: 手動でベクトル検索

python
# 該当チームのチケットIDを直接指定して取得
specific_ticket = vector_db.get_by_id("該当チームのチケットID")

if specific_ticket is None:
    print("❌ データが格納されてない！")
else:
    print(f"✅ データはある: {specific_ticket}")
よくあるパターン予想
😅 パターン1: データが入ってない
python
# 格納時の条件分岐でミスってる？
for ticket in jira_tickets:
    if ticket.status == "完了":  # ← 該当チームは「クローズ」って書いてるとか
        store_to_vectordb(ticket)
😅 パターン2: チーム名の取得方法が違う
python
# 他チーム: assignee.team_name で取得
# 該当チーム: custom_field["team"] で取得
# → 格納時と検索時で取得方法が違ってズレてる
😅 パターン3: 極端に件数が少ない
python
# 53件の内訳
インフラ: 25件
開発: 20件
DB: 7件
該当チーム: 1件  ← これじゃ出ない！
1件しかないと、Top-5に入る確率めっちゃ低いから！

今すぐやってほしいこと
ステップ1: データ確認

python
# 該当チームのチケット、何件格納されてる？
team_tickets = [検索してカウント]
print(f"該当チーム: {len(team_tickets)}件")
ステップ2: 手動検索

python
# 該当チームの代表的なチケット1つで検索
# Top-20 の結果を全部見る
ステップ3: メタデータ確認

python
# 該当チームのチケット1つを取り出して
# metadata を全部ダンプしてみる
print(json.dumps(ticket.metadata, indent=2, ensure_ascii=False))
この3つやってみて、結果教えて！

何件格納されてるか
手動検索で何位に出てくるか
メタデータがどうなってるか
そしたら原因特定できると思う！🔍✨

どのチームが出てこないの？気になる～！
