pythonã«ã¦ã€‚

ãƒ»7za.exeã‚’ä½¿ç”¨ã—ãŸåœ§ç¸®ãƒ•ã‚¡ã‚¤ãƒ«ã®è§£å‡
ãƒ»dlt-converter.exeã‚’ä½¿ç”¨ã—ãŸdltãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚³ãƒ³ãƒãƒ¼ãƒˆ
ãƒ»pythonã«ã¦å®Ÿè£…ã—ãŸã¨ã‚ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å¤‰æ›ã™ã‚‹é–¢æ•°

ä»¥ä¸Šã®ã‚‚ã®ãŒã‚ã‚Šã¾ã™ã€‚

ä¸¦åˆ—å‡¦ç†ã®å®Ÿè£…ã‚’ã—ã‚ˆã†ã¨è€ƒãˆã¦ãŠã‚Šã¾ã™ã€‚
å„ã€…ã«ä¸¦åˆ—åŒ–å‡¦ç†ã‚’å®Ÿè£…ã™ã¹ãã‹ã€ä¸¦åˆ—åŒ–å‡¦ç†ã‚’æŠ½è±¡åŒ–ã™ã¹ãã‹

2æœˆ5æ—¥
ã‚„ã£ã»ãƒ¼ï¼ä¸¦åˆ—å‡¦ç†ã®è¨­è¨ˆã«ã¤ã„ã¦æ‚©ã‚“ã§ã‚‹ã‚“ã ã­ï½âœ¨

ã“ã‚Œã¯ã•ã€æŠ½è±¡åŒ–ä¸€æŠã ã¨æ€ã†ã‚ˆï¼ç†ç”±ã‚’èª¬æ˜ã™ã‚‹ã­ğŸ’ª

æŠ½è±¡åŒ–ã™ã¹ãç†ç”±
å‡¦ç†ãƒ‘ã‚¿ãƒ¼ãƒ³ãŒã»ã¼åŒã˜
ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å…¥åŠ›ã¨ã—ã¦å—ã‘å–ã‚‹
ãªã‚“ã‚‰ã‹ã®å¤‰æ›å‡¦ç†ã‚’å®Ÿè¡Œ
çµæœã‚’å‡ºåŠ›
ã“ã®3ã¤ã¨ã‚‚åŸºæœ¬çš„ãªæµã‚Œã¯ä¸€ç·’ã˜ã‚ƒã‚“ï¼Ÿ
ãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹æ€§ãŒçˆ†ä¸ŠãŒã‚Š
ä¸¦åˆ—å‡¦ç†ã®ãƒã‚°ä¿®æ­£ãŒ1ç®‡æ‰€ã§æ¸ˆã‚€
ãƒ­ã‚°å‡ºåŠ›ã€ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã‚‚çµ±ä¸€ã§ãã‚‹
ã‚ã¨ã‹ã‚‰ä¸¦åˆ—æ•°ã®èª¿æ•´ã¨ã‹ã‚‚æ¥½ã¡ã‚“
ã‚³ãƒ¼ãƒ‰ã®é‡è¤‡ã‚’é¿ã‘ã‚‰ã‚Œã‚‹
å„å‡¦ç†ã§åŒã˜ã‚ˆã†ãªä¸¦åˆ—åŒ–ã‚³ãƒ¼ãƒ‰æ›¸ãã®ãƒ€ãƒ«ã„ã§ã—ã‚‡ï¼Ÿ
DRYåŸå‰‡ï¼ˆDon't Repeat Yourselfï¼‰ã ã‚ˆã­ï½
å®Ÿè£…ã‚¤ãƒ¡ãƒ¼ã‚¸
python
from concurrent.futures import ProcessPoolExecutor, ThreadPoolExecutor
from pathlib import Path
from typing import Callable, List, Any
import subprocess

class ParallelProcessor:
    """ä¸¦åˆ—å‡¦ç†ã‚’æŠ½è±¡åŒ–ã—ãŸã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, max_workers: int = 4, use_process: bool = True):
        self.max_workers = max_workers
        self.executor_class = ProcessPoolExecutor if use_process else ThreadPoolExecutor
    
    def process_files(
        self, 
        files: List[Path], 
        processor_func: Callable[[Path], Any],
        desc: str = "å‡¦ç†ä¸­"
    ) -> List[Any]:
        """
        ãƒ•ã‚¡ã‚¤ãƒ«ãƒªã‚¹ãƒˆã‚’ä¸¦åˆ—å‡¦ç†
        
        Args:
            files: å‡¦ç†å¯¾è±¡ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒªã‚¹ãƒˆ
            processor_func: å„ãƒ•ã‚¡ã‚¤ãƒ«ã«é©ç”¨ã™ã‚‹é–¢æ•°
            desc: é€²æ—è¡¨ç¤ºç”¨ã®èª¬æ˜æ–‡
        """
        results = []
        
        with self.executor_class(max_workers=self.max_workers) as executor:
            futures = {executor.submit(processor_func, file): file 
                      for file in files}
            
            for future in futures:
                try:
                    result = future.result()
                    results.append(result)
                    print(f"âœ… {desc}: {futures[future].name}")
                except Exception as e:
                    print(f"âŒ ã‚¨ãƒ©ãƒ¼ {futures[future].name}: {e}")
                    results.append(None)
        
        return results


# å„å‡¦ç†ã‚’é–¢æ•°ã¨ã—ã¦å®šç¾©
def extract_7z(archive_path: Path) -> Path:
    """7zaã§è§£å‡"""
    output_dir = archive_path.parent / archive_path.stem
    subprocess.run(
        ['7za.exe', 'x', str(archive_path), f'-o{output_dir}', '-y'],
        check=True,
        capture_output=True
    )
    return output_dir

def convert_dlt(dlt_path: Path) -> Path:
    """dltãƒ•ã‚¡ã‚¤ãƒ«ã‚’å¤‰æ›"""
    output_path = dlt_path.with_suffix('.txt')
    subprocess.run(
        ['dlt-converter.exe', '-f', str(dlt_path), '-o', str(output_path)],
        check=True,
        capture_output=True
    )
    return output_path

def custom_convert(file_path: Path) -> Path:
    """ç‹¬è‡ªã®å¤‰æ›å‡¦ç†"""
    # ã‚ãªãŸã®å¤‰æ›é–¢æ•°ã‚’ã“ã“ã«
    output_path = file_path.with_suffix('.converted')
    # å®Ÿéš›ã®å¤‰æ›å‡¦ç†...
    return output_path


# ä½¿ç”¨ä¾‹
if __name__ == '__main__':
    processor = ParallelProcessor(max_workers=4)
    
    # 7zè§£å‡ã‚’ä¸¦åˆ—å®Ÿè¡Œ
    archives = list(Path('.').glob('*.7z'))
    processor.process_files(archives, extract_7z, "7zè§£å‡")
    
    # DLTå¤‰æ›ã‚’ä¸¦åˆ—å®Ÿè¡Œ
    dlt_files = list(Path('.').glob('*.dlt'))
    processor.process_files(dlt_files, convert_dlt, "DLTå¤‰æ›")
    
    # ã‚«ã‚¹ã‚¿ãƒ å¤‰æ›ã‚’ä¸¦åˆ—å®Ÿè¡Œ
    custom_files = list(Path('.').glob('*.dat'))
    processor.process_files(custom_files, custom_convert, "ã‚«ã‚¹ã‚¿ãƒ å¤‰æ›")
ã‚‚ã£ã¨é«˜æ©Ÿèƒ½ç‰ˆã‚‚ä½œã‚Œã‚‹ã‚ˆï¼
python
from dataclasses import dataclass
from enum import Enum
import logging

class ProcessType(Enum):
    THREAD = "thread"
    PROCESS = "process"

@dataclass
class ProcessConfig:
    max_workers: int = 4
    process_type: ProcessType = ProcessType.PROCESS
    timeout: int = 300  # ç§’
    retry_count: int = 3

class AdvancedParallelProcessor:
    """ã‚‚ã£ã¨é«˜æ©Ÿèƒ½ãªä¸¦åˆ—ãƒ—ãƒ­ã‚»ãƒƒã‚µ"""
    
    def __init__(self, config: ProcessConfig = ProcessConfig()):
        self.config = config
        self.logger = logging.getLogger(__name__)
    
    def process_with_progress(
        self,
        files: List[Path],
        processor_func: Callable,
        progress_callback: Callable[[int, int], None] = None
    ):
        """é€²æ—ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯ä»˜ãä¸¦åˆ—å‡¦ç†"""
        # tqdmã¨ã‹ã¨é€£æºã§ãã‚‹ã‚ˆã†ã«ã™ã‚‹
        pass
    
    def process_with_retry(self, file: Path, func: Callable, retry: int = 0):
        """ãƒªãƒˆãƒ©ã‚¤æ©Ÿèƒ½ä»˜ãå‡¦ç†"""
        try:
            return func(file)
        except Exception as e:
            if retry < self.config.retry_count:
                self.logger.warning(f"ãƒªãƒˆãƒ©ã‚¤ {retry + 1}/{self.config.retry_count}: {file}")
                return self.process_with_retry(file, func, retry + 1)
            else:
                self.logger.error(f"å‡¦ç†å¤±æ•—: {file} - {e}")
                raise
ã¾ã¨ã‚
å„å‡¦ç†ã«å€‹åˆ¥å®Ÿè£…ã™ã‚‹ã®ã¯ã‚¢ãƒ³ãƒãƒ‘ã‚¿ãƒ¼ãƒ³ã ã‚ˆï¼

âœ¨ æŠ½è±¡åŒ–ã®ãƒ¡ãƒªãƒƒãƒˆ

ã‚³ãƒ¼ãƒ‰ã®å†åˆ©ç”¨æ€§UP
ãƒã‚°ä¿®æ­£ãŒ1ç®‡æ‰€ã§æ¸ˆã‚€
æ–°ã—ã„å‡¦ç†ã‚¿ã‚¤ãƒ—ã®è¿½åŠ ãŒè¶…ç°¡å˜
ãƒ†ã‚¹ãƒˆã‚‚æ›¸ãã‚„ã™ã„
ä¸¦åˆ—æ•°ã®èª¿æ•´ã¨ã‹ãƒ­ã‚°è¨­å®šã‚‚ä¸€å…ƒç®¡ç†
ã©ã†ï¼Ÿã“ã®æ–¹å‘æ€§ã§é€²ã‚ã¦ã¿ãªã„ï¼ŸğŸ˜Š
å¿…è¦ãªã‚‰æ›´ã«è©³ç´°ãªå®Ÿè£…ä¾‹ã‚‚å‡ºã›ã‚‹ã‚ˆãƒ¼ï¼

threadpoolexecuterã‚’ä½¿ç”¨ã—ã¦ã®å®Ÿè£…ã¯å¯èƒ½ã§ã™ã‹

2æœˆ5æ—¥
ã‚‚ã¡ã‚ã‚“å¯èƒ½ã ã‚ˆãƒ¼ï¼ã£ã¦ã„ã†ã‹ã€ã•ã£ãã®ã‚³ãƒ¼ãƒ‰è¦‹ã¦ãã‚ŒãŸï¼ŸğŸ˜Š

ThreadPoolExecutorã‚‚ProcessPoolExecutorã‚‚ä¸¡æ–¹ä½¿ãˆã‚‹ã‚ˆã†ã«ã—ã¦ã‚ã‚‹ã‚“ã ï¼

ThreadPoolExecutorã‚’ä½¿ã†å ´åˆ
python
from concurrent.futures import ThreadPoolExecutor
from pathlib import Path
from typing import Callable, List, Any
import subprocess

class ParallelProcessor:
    """ThreadPoolExecutorãƒ™ãƒ¼ã‚¹ã®ä¸¦åˆ—å‡¦ç†ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, max_workers: int = 4):
        self.max_workers = max_workers
    
    def process_files(
        self, 
        files: List[Path], 
        processor_func: Callable[[Path], Any],
        desc: str = "å‡¦ç†ä¸­"
    ) -> List[Any]:
        """ThreadPoolExecutorã§ä¸¦åˆ—å‡¦ç†"""
        results = []
        
        with ThreadPoolExecutor(max_workers=self.max_workers) as executor:
            # å…¨ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚µãƒ–ãƒŸãƒƒãƒˆ
            future_to_file = {
                executor.submit(processor_func, file): file 
                for file in files
            }
            
            # å®Œäº†é †ã«çµæœã‚’å–å¾—
            from concurrent.futures import as_completed
            for future in as_completed(future_to_file):
                file = future_to_file[future]
                try:
                    result = future.result()
                    results.append(result)
                    print(f"âœ… {desc}: {file.name} å®Œäº†ï¼")
                except Exception as e:
                    print(f"âŒ ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿ {file.name}: {e}")
                    results.append(None)
        
        return results


# ä½¿ç”¨ä¾‹
def extract_7z(archive_path: Path) -> Path:
    """7zaã§è§£å‡"""
    output_dir = archive_path.parent / archive_path.stem
    output_dir.mkdir(exist_ok=True)
    
    result = subprocess.run(
        ['7za.exe', 'x', str(archive_path), f'-o{output_dir}', '-y'],
        check=True,
        capture_output=True,
        text=True
    )
    return output_dir

def convert_dlt(dlt_path: Path) -> Path:
    """dltãƒ•ã‚¡ã‚¤ãƒ«ã‚’å¤‰æ›"""
    output_path = dlt_path.with_suffix('.txt')
    
    result = subprocess.run(
        ['dlt-converter.exe', '-f', str(dlt_path), '-o', str(output_path)],
        check=True,
        capture_output=True,
        text=True
    )
    return output_path


# å®Ÿè¡Œ
if __name__ == '__main__':
    processor = ParallelProcessor(max_workers=8)
    
    # 7zè§£å‡
    archives = list(Path('.').glob('*.7z'))
    print(f"ğŸ—œï¸ {len(archives)}å€‹ã®ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–ã‚’è§£å‡ã™ã‚‹ã‚ˆï½")
    processor.process_files(archives, extract_7z, "7zè§£å‡")
    
    # DLTå¤‰æ›
    dlt_files = list(Path('.').glob('*.dlt'))
    print(f"ğŸ“ {len(dlt_files)}å€‹ã®DLTãƒ•ã‚¡ã‚¤ãƒ«ã‚’å¤‰æ›ã™ã‚‹ã‚ˆï½")
    processor.process_files(dlt_files, convert_dlt, "DLTå¤‰æ›")
ThreadPoolExecutor vs ProcessPoolExecutor
ä½¿ã„åˆ†ã‘ã®ãƒã‚¤ãƒ³ãƒˆæ•™ãˆã‚‹ã­ï¼

ThreadPoolExecutorä½¿ã†ã¹ãæ™‚ âœ…
I/Oå¾…ã¡ãŒå¤šã„å‡¦ç†ï¼ˆä»Šå›ã®ã‚±ãƒ¼ã‚¹ã¯ã“ã‚Œï¼ï¼‰
å¤–éƒ¨ãƒ—ãƒ­ã‚°ãƒ©ãƒ å®Ÿè¡Œï¼ˆ7za.exe, dlt-converter.exeï¼‰
ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿æ›¸ã
ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯é€šä¿¡
ãƒ¡ãƒ¢ãƒªåŠ¹ç‡ãŒè‰¯ã„
èµ·å‹•ãŒé€Ÿã„
ãƒ‡ãƒ¼ã‚¿å…±æœ‰ãŒç°¡å˜
ProcessPoolExecutorä½¿ã†ã¹ãæ™‚
CPUè² è·ãŒé«˜ã„å‡¦ç†
ç”»åƒå‡¦ç†
æ•°å€¤è¨ˆç®—
ãƒ‡ãƒ¼ã‚¿è§£æ
GILï¼ˆGlobal Interpreter Lockï¼‰ã‚’å›é¿ã—ãŸã„æ™‚
ã‚ãªãŸã®å ´åˆã¯ ThreadPoolExecutor ãŒæœ€é©ï¼
ç†ç”±ï¼š

subprocesså‘¼ã³å‡ºã—ãŒãƒ¡ã‚¤ãƒ³ â†’ I/Oå¾…ã¡ãŒå¤§åŠ
è¤‡æ•°ã®å¤–éƒ¨ãƒ—ãƒ­ã‚°ãƒ©ãƒ ã‚’å®Ÿè¡Œ â†’ GILã®å½±éŸ¿ãªã—
ãƒ¡ãƒ¢ãƒªåŠ¹ç‡ãŒè‰¯ã„ â†’ ãƒ—ãƒ­ã‚»ã‚¹èµ·å‹•ã‚³ã‚¹ãƒˆãªã—
python
# ã‚ˆã‚Šå®Ÿè·µçš„ãªå®Ÿè£…ä¾‹
from concurrent.futures import ThreadPoolExecutor, as_completed
from pathlib import Path
from typing import Callable, List, Dict, Any
import subprocess
import time

class FileProcessor:
    """ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†ã®ä¸¦åˆ—å®Ÿè¡Œãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼"""
    
    def __init__(self, max_workers: int = 8):
        self.max_workers = max_workers
        self.results: List[Dict[str, Any]] = []
    
    def process_batch(
        self, 
        files: List[Path], 
        processor_func: Callable[[Path], Any],
        desc: str = "å‡¦ç†"
    ) -> Dict[str, Any]:
        """ãƒãƒƒãƒå‡¦ç†ã‚’å®Ÿè¡Œã—ã¦çµ±è¨ˆæƒ…å ±ã‚’è¿”ã™"""
        
        start_time = time.time()
        success_count = 0
        error_count = 0
        
        print(f"\n{'='*50}")
        print(f"ğŸš€ {desc}é–‹å§‹: {len(files)}ãƒ•ã‚¡ã‚¤ãƒ«")
        print(f"âš™ï¸  ä¸¦åˆ—åº¦: {self.max_workers}")
        print(f"{'='*50}\n")
        
        with ThreadPoolExecutor(max_workers=self.max_workers) as executor:
            future_to_file = {
                executor.submit(processor_func, file): file 
                for file in files
            }
            
            for future in as_completed(future_to_file):
                file = future_to_file[future]
                try:
                    result = future.result(timeout=300)  # 5åˆ†ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ
                    success_count += 1
                    print(f"âœ… [{success_count}/{len(files)}] {file.name}")
                except subprocess.TimeoutExpired:
                    error_count += 1
                    print(f"â±ï¸  ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ: {file.name}")
                except subprocess.CalledProcessError as e:
                    error_count += 1
                    print(f"âŒ å‡¦ç†å¤±æ•—: {file.name}")
                    print(f"   ã‚¨ãƒ©ãƒ¼: {e.stderr if e.stderr else e}")
                except Exception as e:
                    error_count += 1
                    print(f"âŒ äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼: {file.name} - {e}")
        
        elapsed_time = time.time() - start_time
        
        stats = {
            'desc': desc,
            'total': len(files),
            'success': success_count,
            'error': error_count,
            'elapsed_time': elapsed_time,
            'avg_time': elapsed_time / len(files) if files else 0
        }
        
        print(f"\n{'='*50}")
        print(f"ğŸ“Š {desc}å®Œäº†")
        print(f"âœ… æˆåŠŸ: {success_count}/{len(files)}")
        print(f"âŒ å¤±æ•—: {error_count}/{len(files)}")
        print(f"â±ï¸  æ‰€è¦æ™‚é–“: {elapsed_time:.2f}ç§’")
        print(f"ğŸ“ˆ å¹³å‡å‡¦ç†æ™‚é–“: {stats['avg_time']:.2f}ç§’/ãƒ•ã‚¡ã‚¤ãƒ«")
        print(f"{'='*50}\n")
        
        return stats


# ä½¿ç”¨ä¾‹
if __name__ == '__main__':
    processor = FileProcessor(max_workers=8)
    
    # 7zè§£å‡
    archives = list(Path('./archives').glob('*.7z'))
    if archives:
        stats1 = processor.process_batch(archives, extract_7z, "7zè§£å‡")
    
    # DLTå¤‰æ›
    dlt_files = list(Path('./dlt').glob('*.dlt'))
    if dlt_files:
        stats2 = processor.process_batch(dlt_files, convert_dlt, "DLTå¤‰æ›")
ä¸¦åˆ—æ•°ã®æ±ºã‚æ–¹
python
import os

# CPUã‚³ã‚¢æ•°ãƒ™ãƒ¼ã‚¹
max_workers = os.cpu_count()  # ä¾‹: 8ã‚³ã‚¢

# I/Oå¾…ã¡ãŒå¤šã„ã‹ã‚‰ã‚‚ã£ã¨å¢—ã‚„ã—ã¦ã‚‚OK
max_workers = os.cpu_count() * 2  # 16ã‚¹ãƒ¬ãƒƒãƒ‰

# å®Ÿé¨“ã—ã¦æœ€é©å€¤ã‚’è¦‹ã¤ã‘ã‚‹
for workers in [4, 8, 16, 32]:
    processor = FileProcessor(max_workers=workers)
    # å‡¦ç†æ™‚é–“ã‚’è¨ˆæ¸¬ã—ã¦æ¯”è¼ƒ
ã©ã†ï¼ŸThreadPoolExecutorã§ãƒãƒƒãƒãƒªå‹•ãã‚ˆï¼ğŸ’ªâœ¨
ä½•ã‹è³ªå•ã‚ã£ãŸã‚‰èã„ã¦ã­ï½ï¼

ä¸¦åˆ—ã®è©±ã‹ã‚‰ãã‚Œã¾ã™ãŒã€dlt-viewer.exeï¼Œ7za.exeãªã©ã€å¤–éƒ¨ãƒ„ãƒ¼ãƒ«ã‚’ä½¿ã†ã£ã¦éƒ¨åˆ†ã‚’æŠ½è±¡åŒ–ã—ãŸã»ã†ãŒã„ã„?

2æœˆ5æ—¥
ã‚ãƒ¼ã€ã‚ã£ã¡ã‚ƒã„ã„è³ªå•ï¼ğŸ¤”âœ¨

ã“ã‚Œã¯çµ¶å¯¾ã«æŠ½è±¡åŒ–ã™ã¹ãã ã¨æ€ã†ï¼ç†ç”±ã‚’èª¬æ˜ã™ã‚‹ã­ğŸ’ª

æŠ½è±¡åŒ–ã™ã¹ãç†ç”±
ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ãŒçµ±ä¸€ã§ãã‚‹
å¤–éƒ¨ãƒ„ãƒ¼ãƒ«ã£ã¦çµæ§‹ã‚¨ãƒ©ãƒ¼èµ·ã“ã™ã˜ã‚ƒã‚“ï¼Ÿ
ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã€å®Ÿè¡Œãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚‰ãªã„ã€æ¨©é™ã‚¨ãƒ©ãƒ¼ã¨ã‹
æ¯å›åŒã˜ã‚³ãƒ¼ãƒ‰æ›¸ãã®ãƒ€ãƒ«ã„
ãƒ­ã‚°ãŒå–ã‚Šã‚„ã™ã„
ã©ã®ã‚³ãƒãƒ³ãƒ‰å®Ÿè¡Œã—ãŸã‹
å®Ÿè¡Œæ™‚é–“
æ¨™æº–å‡ºåŠ›/æ¨™æº–ã‚¨ãƒ©ãƒ¼å‡ºåŠ›
ãƒ†ã‚¹ãƒˆãŒæ¥½
ãƒ¢ãƒƒã‚¯åŒ–ã—ã‚„ã™ã„
å¤–éƒ¨ãƒ„ãƒ¼ãƒ«ãªã—ã§ãƒ†ã‚¹ãƒˆã§ãã‚‹
ãƒ„ãƒ¼ãƒ«ã®ãƒ‘ã‚¹ç®¡ç†ãŒä¸€å…ƒåŒ–
ç’°å¢ƒå¤‰æ•°ã§åˆ‡ã‚Šæ›¿ãˆã¨ã‹
å®Ÿè¡Œãƒ•ã‚¡ã‚¤ãƒ«ã®å­˜åœ¨ãƒã‚§ãƒƒã‚¯ã¨ã‹
å®Ÿè£…ä¾‹
python
from pathlib import Path
from typing import List, Optional, Dict, Any
import subprocess
import logging
from dataclasses import dataclass
from abc import ABC, abstractmethod
import shutil

@dataclass
class CommandResult:
    """ã‚³ãƒãƒ³ãƒ‰å®Ÿè¡Œçµæœ"""
    success: bool
    stdout: str
    stderr: str
    return_code: int
    elapsed_time: float
    command: str

class ExternalToolExecutor:
    """å¤–éƒ¨ãƒ„ãƒ¼ãƒ«å®Ÿè¡Œã®æŠ½è±¡åŒ–ã‚¯ãƒ©ã‚¹"""
    
    def __init__(
        self, 
        tool_path: Path,
        timeout: int = 300,
        encoding: str = 'utf-8'
    ):
        self.tool_path = Path(tool_path)
        self.timeout = timeout
        self.encoding = encoding
        self.logger = logging.getLogger(self.__class__.__name__)
        
        # å®Ÿè¡Œãƒ•ã‚¡ã‚¤ãƒ«ã®å­˜åœ¨ãƒã‚§ãƒƒã‚¯
        if not self.tool_path.exists():
            raise FileNotFoundError(f"ãƒ„ãƒ¼ãƒ«ãŒè¦‹ã¤ã‹ã‚‰ãªã„ã‚ˆ: {self.tool_path}")
    
    def execute(
        self, 
        args: List[str],
        cwd: Optional[Path] = None,
        env: Optional[Dict[str, str]] = None,
        check: bool = True
    ) -> CommandResult:
        """
        å¤–éƒ¨ãƒ„ãƒ¼ãƒ«ã‚’å®Ÿè¡Œ
        
        Args:
            args: ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³å¼•æ•°ã®ãƒªã‚¹ãƒˆ
            cwd: ä½œæ¥­ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
            env: ç’°å¢ƒå¤‰æ•°
            check: ã‚¨ãƒ©ãƒ¼æ™‚ã«ä¾‹å¤–ã‚’æŠ•ã’ã‚‹ã‹
        """
        import time
        
        command = [str(self.tool_path)] + args
        command_str = ' '.join(command)
        
        self.logger.info(f"ğŸš€ å®Ÿè¡Œ: {command_str}")
        
        start_time = time.time()
        
        try:
            result = subprocess.run(
                command,
                cwd=cwd,
                env=env,
                capture_output=True,
                text=True,
                encoding=self.encoding,
                timeout=self.timeout,
                check=check
            )
            
            elapsed = time.time() - start_time
            
            self.logger.info(f"âœ… å®Œäº† ({elapsed:.2f}ç§’): {command_str}")
            
            return CommandResult(
                success=result.returncode == 0,
                stdout=result.stdout,
                stderr=result.stderr,
                return_code=result.returncode,
                elapsed_time=elapsed,
                command=command_str
            )
            
        except subprocess.TimeoutExpired as e:
            elapsed = time.time() - start_time
            self.logger.error(f"â±ï¸  ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ ({self.timeout}ç§’): {command_str}")
            
            return CommandResult(
                success=False,
                stdout=e.stdout.decode(self.encoding) if e.stdout else "",
                stderr=e.stderr.decode(self.encoding) if e.stderr else "",
                return_code=-1,
                elapsed_time=elapsed,
                command=command_str
            )
            
        except subprocess.CalledProcessError as e:
            elapsed = time.time() - start_time
            self.logger.error(f"âŒ ã‚¨ãƒ©ãƒ¼ (code={e.returncode}): {command_str}")
            self.logger.error(f"stderr: {e.stderr}")
            
            return CommandResult(
                success=False,
                stdout=e.stdout,
                stderr=e.stderr,
                return_code=e.returncode,
                elapsed_time=elapsed,
                command=command_str
            )
        
        except Exception as e:
            elapsed = time.time() - start_time
            self.logger.error(f"ğŸ’¥ äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼: {command_str} - {e}")
            raise


class SevenZipExecutor(ExternalToolExecutor):
    """7-Zipå°‚ç”¨ã®ãƒ©ãƒƒãƒ‘ãƒ¼"""
    
    def __init__(self, tool_path: Path = Path("7za.exe"), **kwargs):
        super().__init__(tool_path, **kwargs)
    
    def extract(
        self, 
        archive_path: Path, 
        output_dir: Path,
        password: Optional[str] = None,
        overwrite: bool = True
    ) -> CommandResult:
        """ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–ã‚’è§£å‡"""
        
        output_dir.mkdir(parents=True, exist_ok=True)
        
        args = ['x', str(archive_path), f'-o{output_dir}']
        
        if overwrite:
            args.append('-y')  # ã™ã¹ã¦ä¸Šæ›¸ã
        
        if password:
            args.append(f'-p{password}')
        
        return self.execute(args)
    
    def compress(
        self,
        target: Path,
        output_archive: Path,
        compression_level: int = 5,
        archive_type: str = '7z'
    ) -> CommandResult:
        """ãƒ•ã‚¡ã‚¤ãƒ«/ãƒ•ã‚©ãƒ«ãƒ€ã‚’åœ§ç¸®"""
        
        args = [
            'a',  # add
            f'-t{archive_type}',
            f'-mx={compression_level}',  # 0-9
            str(output_archive),
            str(target)
        ]
        
        return self.execute(args)
    
    def list_contents(self, archive_path: Path) -> CommandResult:
        """ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–ã®ä¸­èº«ã‚’ãƒªã‚¹ãƒˆè¡¨ç¤º"""
        return self.execute(['l', str(archive_path)])


class DltConverterExecutor(ExternalToolExecutor):
    """DLTã‚³ãƒ³ãƒãƒ¼ã‚¿ãƒ¼å°‚ç”¨ã®ãƒ©ãƒƒãƒ‘ãƒ¼"""
    
    def __init__(self, tool_path: Path = Path("dlt-converter.exe"), **kwargs):
        super().__init__(tool_path, **kwargs)
    
    def convert(
        self,
        dlt_path: Path,
        output_path: Optional[Path] = None,
        output_format: str = 'txt'
    ) -> CommandResult:
        """DLTãƒ•ã‚¡ã‚¤ãƒ«ã‚’å¤‰æ›"""
        
        if output_path is None:
            output_path = dlt_path.with_suffix(f'.{output_format}')
        
        args = ['-f', str(dlt_path), '-o', str(output_path)]
        
        return self.execute(args)


# ãƒ„ãƒ¼ãƒ«ãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
class ToolManager:
    """è¤‡æ•°ã®å¤–éƒ¨ãƒ„ãƒ¼ãƒ«ã‚’ç®¡ç†"""
    
    def __init__(self, tools_dir: Optional[Path] = None):
        self.tools_dir = tools_dir or Path('.')
        self.tools: Dict[str, ExternalToolExecutor] = {}
        self.logger = logging.getLogger(__name__)
    
    def register_tool(self, name: str, executor: ExternalToolExecutor):
        """ãƒ„ãƒ¼ãƒ«ã‚’ç™»éŒ²"""
        self.tools[name] = executor
        self.logger.info(f"ğŸ“¦ ãƒ„ãƒ¼ãƒ«ç™»éŒ²: {name} -> {executor.tool_path}")
    
    def get_tool(self, name: str) -> ExternalToolExecutor:
        """ãƒ„ãƒ¼ãƒ«ã‚’å–å¾—"""
        if name not in self.tools:
            raise KeyError(f"ãƒ„ãƒ¼ãƒ«ãŒæœªç™»éŒ²ã ã‚ˆ: {name}")
        return self.tools[name]
    
    def check_all_tools(self) -> Dict[str, bool]:
        """å…¨ãƒ„ãƒ¼ãƒ«ã®å­˜åœ¨ãƒã‚§ãƒƒã‚¯"""
        results = {}
        for name, tool in self.tools.items():
            exists = tool.tool_path.exists()
            results[name] = exists
            status = "âœ…" if exists else "âŒ"
            self.logger.info(f"{status} {name}: {tool.tool_path}")
        return results


# ä½¿ç”¨ä¾‹
if __name__ == '__main__':
    logging.basicConfig(level=logging.INFO)
    
    # æ–¹æ³•1: ç›´æ¥ä½¿ç”¨
    sevenzip = SevenZipExecutor(Path('7za.exe'))
    result = sevenzip.extract(
        archive_path=Path('test.7z'),
        output_dir=Path('extracted')
    )
    print(f"çµæœ: {result.success}, æ‰€è¦æ™‚é–“: {result.elapsed_time:.2f}ç§’")
    
    dlt_converter = DltConverterExecutor(Path('dlt-converter.exe'))
    result = dlt_converter.convert(Path('test.dlt'))
    
    # æ–¹æ³•2: ãƒ„ãƒ¼ãƒ«ãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼ä½¿ç”¨
    manager = ToolManager()
    manager.register_tool('7zip', SevenZipExecutor(Path('7za.exe')))
    manager.register_tool('dlt', DltConverterExecutor(Path('dlt-converter.exe')))
    
    # ãƒ„ãƒ¼ãƒ«ã®å­˜åœ¨ãƒã‚§ãƒƒã‚¯
    manager.check_all_tools()
    
    # ãƒ„ãƒ¼ãƒ«å–å¾—ã—ã¦ä½¿ç”¨
    sevenzip = manager.get_tool('7zip')
    sevenzip.extract(Path('archive.7z'), Path('output'))
ä¸¦åˆ—å‡¦ç†ã¨çµ„ã¿åˆã‚ã›ã‚‹
python
from concurrent.futures import ThreadPoolExecutor
from typing import List

class ParallelFileProcessor:
    """ä¸¦åˆ—å‡¦ç† + å¤–éƒ¨ãƒ„ãƒ¼ãƒ«å®Ÿè¡Œ"""
    
    def __init__(self, tool_manager: ToolManager, max_workers: int = 8):
        self.tool_manager = tool_manager
        self.max_workers = max_workers
    
    def extract_archives_parallel(self, archives: List[Path], output_base: Path):
        """è¤‡æ•°ã®ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–ã‚’ä¸¦åˆ—è§£å‡"""
        
        sevenzip = self.tool_manager.get_tool('7zip')
        
        def extract_one(archive: Path):
            output_dir = output_base / archive.stem
            return sevenzip.extract(archive, output_dir)
        
        with ThreadPoolExecutor(max_workers=self.max_workers) as executor:
            results = list(executor.map(extract_one, archives))
        
        # çµæœã‚’é›†è¨ˆ
        success = sum(1 for r in results if r.success)
        print(f"âœ… æˆåŠŸ: {success}/{len(archives)}")
        
        return results
    
    def convert_dlts_parallel(self, dlt_files: List[Path]):
        """è¤‡æ•°ã®DLTãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¸¦åˆ—å¤‰æ›"""
        
        dlt_converter = self.tool_manager.get_tool('dlt')
        
        def convert_one(dlt_file: Path):
            return dlt_converter.convert(dlt_file)
        
        with ThreadPoolExecutor(max_workers=self.max_workers) as executor:
            results = list(executor.map(convert_one, dlt_files))
        
        success = sum(1 for r in results if r.success)
        print(f"âœ… æˆåŠŸ: {success}/{len(dlt_files)}")
        
        return results


# å®Ÿè¡Œä¾‹
if __name__ == '__main__':
    # ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—
    manager = ToolManager()
    manager.register_tool('7zip', SevenZipExecutor(Path('7za.exe')))
    manager.register_tool('dlt', DltConverterExecutor(Path('dlt-converter.exe')))
    
    # ä¸¦åˆ—å‡¦ç†å®Ÿè¡Œ
    processor = ParallelFileProcessor(manager, max_workers=8)
    
    archives = list(Path('.').glob('*.7z'))
    processor.extract_archives_parallel(archives, Path('./extracted'))
    
    dlt_files = list(Path('.').glob('*.dlt'))
    processor.convert_dlts_parallel(dlt_files)
ãƒ¡ãƒªãƒƒãƒˆã¾ã¨ã‚
âœ¨ æŠ½è±¡åŒ–ã™ã‚‹ã“ã¨ã§

ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ãŒçµ±ä¸€ã•ã‚Œã‚‹
ãƒ­ã‚°ãŒè‡ªå‹•ã§å–ã‚Œã‚‹
ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆç®¡ç†ãŒç°¡å˜
ãƒ†ã‚¹ãƒˆãŒæ›¸ãã‚„ã™ã„ï¼ˆãƒ¢ãƒƒã‚¯åŒ–ã§ãã‚‹ï¼‰
ãƒ„ãƒ¼ãƒ«ã®ãƒ‘ã‚¹ç®¡ç†ãŒæ¥½
æ–°ã—ã„ãƒ„ãƒ¼ãƒ«è¿½åŠ ãŒè¶…ç°¡å˜
ã©ã†ï¼Ÿã“ã®æ–¹å‘æ€§ã§é€²ã‚ã¦ã¿ãªã„ï¼ŸğŸ˜Š
å¿…è¦ãªã‚‰ã‚‚ã£ã¨è©³ç´°ãªå®Ÿè£…ä¾‹ã‚‚å‡ºã›ã‚‹ã‚ˆãƒ¼ï¼
